# This file should be placed in the ocobo-posts repository at:
# .github/workflows/upload-assets.yml

name: Upload Assets to Vercel Blob

on:
  push:
    paths:
      - 'assets/**'  # Trigger when assets are added
      - 'blog/*/assets/**'  # Blog post assets
      - 'stories/*/assets/**'  # Story assets
  workflow_dispatch:  # Allow manual execution

jobs:
  upload-assets:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Get current and previous commit for changed files
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: latest
      
      - name: Install dependencies
        run: |
          pnpm init
          pnpm add @vercel/blob @octokit/rest
      
      - name: Get changed asset files
        id: changes
        run: |
          # Get list of changed image files
          changed_files=$(git diff --name-only --diff-filter=A HEAD~1 HEAD | grep -E '\.(png|jpg|jpeg|svg|webp|gif)$' || true)
          
          if [ -n "$changed_files" ]; then
            echo "Found new asset files:"
            echo "$changed_files"
            
            # Convert to JSON array for processing
            files_json=$(echo "$changed_files" | jq -R -s -c 'split("\n")[:-1]')
            echo "files=$files_json" >> $GITHUB_OUTPUT
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "No new asset files detected"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Upload assets to Vercel Blob
        if: steps.changes.outputs.has_changes == 'true'
        env:
          BLOB_READ_WRITE_TOKEN: ${{ secrets.BLOB_READ_WRITE_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cat << 'EOF' > upload-assets.js
          const { put } = require('@vercel/blob');
          const { readFile } = require('fs/promises');
          const { Octokit } = require('@octokit/rest');
          const path = require('path');
          
          const files = ${{ steps.changes.outputs.files }};
          const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
          
          function getBlobPath(filePath) {
            // Convert file paths to blob storage structure
            // Examples:
            // assets/posts/new-post/image.png -> content/posts/new-post/image.png
            // blog/fr/assets/image.png -> content/posts/[post-folder]/image.png
            
            if (filePath.startsWith('assets/')) {
              return `content/${filePath.replace('assets/', '')}`;
            }
            
            // Handle blog/stories with embedded assets
            if (filePath.includes('/assets/')) {
              const parts = filePath.split('/');
              const type = parts[0]; // blog or stories
              const assetIndex = parts.indexOf('assets');
              const fileName = parts.slice(assetIndex + 1).join('/');
              const folder = parts.slice(1, assetIndex).join('/');
              
              return `content/${type}/${folder}/${fileName}`;
            }
            
            // Fallback
            return `content/misc/${path.basename(filePath)}`;
          }
          
          function getContentType(filename) {
            const ext = filename.toLowerCase().split('.').pop();
            const contentTypes = {
              'png': 'image/png',
              'jpg': 'image/jpeg',
              'jpeg': 'image/jpeg',
              'svg': 'image/svg+xml',
              'webp': 'image/webp',
              'gif': 'image/gif'
            };
            return contentTypes[ext] || 'application/octet-stream';
          }
          
          async function uploadFile(filePath) {
            try {
              const fileBuffer = await readFile(filePath);
              const blobPath = getBlobPath(filePath);
              const contentType = getContentType(filePath);
              
              console.log(`Uploading: ${filePath} -> ${blobPath}`);
              
              const blob = await put(blobPath, fileBuffer, {
                access: 'public',
                contentType,
                addRandomSuffix: false
              });
              
              console.log(`‚úÖ Uploaded: ${blob.url}`);
              return { filePath, blobPath, url: blob.url };
              
            } catch (error) {
              console.error(`‚ùå Failed to upload ${filePath}:`, error.message);
              throw error;
            }
          }
          
          async function updateMarkdownReferences(results) {
            // Update any markdown files that might reference these assets
            for (const result of results) {
              const oldPath = result.filePath.replace(/^assets\//, '/');
              const newUrl = result.url;
              
              console.log(`Would update references: ${oldPath} -> ${newUrl}`);
              // TODO: Implement automatic markdown updates if needed
            }
          }
          
          async function main() {
            const results = [];
            
            for (const file of files) {
              if (file && file.trim()) {
                try {
                  const result = await uploadFile(file.trim());
                  results.push(result);
                  
                  // Small delay between uploads
                  await new Promise(resolve => setTimeout(resolve, 500));
                } catch (error) {
                  console.error(`Failed to process ${file}:`, error.message);
                }
              }
            }
            
            if (results.length > 0) {
              // Create a summary comment on the commit
              const commitSha = process.env.GITHUB_SHA;
              const summary = results.map(r => `- ${r.filePath} ‚Üí [${r.blobPath}](${r.url})`).join('\n');
              
              try {
                await octokit.rest.repos.createCommitComment({
                  owner: process.env.GITHUB_REPOSITORY.split('/')[0],
                  repo: process.env.GITHUB_REPOSITORY.split('/')[1],  
                  commit_sha: commitSha,
                  body: `üöÄ **Assets uploaded to Vercel Blob**\n\n${summary}\n\n*Uploaded ${results.length} file(s)*`
                });
              } catch (error) {
                console.warn('Could not create commit comment:', error.message);
              }
              
              console.log(`\n‚úÖ Successfully uploaded ${results.length} files to Vercel Blob`);
              
              // Update markdown references if needed
              await updateMarkdownReferences(results);
            }
          }
          
          main().catch(error => {
            console.error('Upload failed:', error);
            process.exit(1);
          });
          EOF
          
          node upload-assets.js
      
      - name: Trigger website revalidation
        if: steps.changes.outputs.has_changes == 'true'
        env:
          VERCEL_WEBHOOK_URL: ${{ secrets.VERCEL_WEBHOOK_URL }}
        run: |
          if [ -n "$VERCEL_WEBHOOK_URL" ]; then
            curl -X POST "$VERCEL_WEBHOOK_URL" \
              -H "Content-Type: application/json" \
              -d '{
                "reason": "New assets uploaded to blob storage",
                "files": ${{ steps.changes.outputs.files }}
              }'
            echo "‚úÖ Website revalidation triggered"
          else
            echo "‚ÑπÔ∏è  No webhook URL configured, skipping website revalidation"
          fi